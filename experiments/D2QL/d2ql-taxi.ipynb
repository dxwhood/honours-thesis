{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Q-Learning for Taxi Environment\n",
    "\n",
    "The Taxi-v3 environment from OpenAI Gym is a discrete, reinforcement learning task where an agent must pick up and drop off a passenger at the right location as efficiently as possible. Our objective is to adapt the Diffusion Q-Learning algorithm to this environment and validate its performance using our collected offline expert dataset taxi_q_expert_dataset.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# Additional libraries as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "dataset = pd.read_csv('taxi_q_expert_dataset.csv')\n",
    "#remove header\n",
    "#dataset = dataset[1:]\n",
    "\n",
    "\n",
    "#Define the environment\n",
    "env = gym.make('Taxi-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/damien/honours-thesis/experiments/D2QL/d2ql-taxi.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/damien/honours-thesis/experiments/D2QL/d2ql-taxi.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#dataset test\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/damien/honours-thesis/experiments/D2QL/d2ql-taxi.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset\u001b[39m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#dataset test\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Exploration\n",
    "\n",
    "To effectively train the Diffusion Q-Learning model, we first need to preprocess and understand the offline expert data. This step involves exploring the distribution of states, actions, and rewards, and formatting the data into a structure format for training and testing the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion from Integer observation to Analog Bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2analog(x, n=8):\n",
    "    # Convert an integer to a PyTorch tensor\n",
    "    x_tensor = torch.tensor([x], dtype=torch.int32)\n",
    "\n",
    "    # Convert integers into the corresponding binary bits.\n",
    "    shifts = torch.arange(n - 1, -1, -1, dtype=x_tensor.dtype)\n",
    "    x_tensor = torch.bitwise_right_shift(x_tensor, shifts)\n",
    "    x_tensor = torch.remainder(x_tensor, 2)\n",
    "\n",
    "    # Convert the binary bits into the corresponding analog values.\n",
    "    x_tensor = x_tensor.type(torch.float32)\n",
    "    x_tensor = 2 * x_tensor - 1\n",
    "\n",
    "    return x_tensor  \n",
    "\n",
    "\n",
    "def analog2int(x):\n",
    "    # Convert an analog bit representation back to an integer\n",
    "    x = (x + 1) / 2  # Convert from [-1, 1] to [0, 1]\n",
    "    x = torch.round(x).type(torch.int32)  # Round and convert to int\n",
    "    # Convert binary bits back to integer\n",
    "    int_val = 0\n",
    "    for i, bit in enumerate(reversed(x)):\n",
    "        int_val += bit.item() * (2 ** i)\n",
    "    return int_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -1., -1., -1.,  1.,  1., -1., -1.])\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(int2analog(12))\n",
    "print(analog2int(int2analog(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, state_bit_length, action_bit_length):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Data must be a Pandas DataFrame\")\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_columns = ['state', 'action', 'reward', 'next_state', 'done']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Data must contain the following columns: {required_columns}\")\n",
    "\n",
    "    # Apply int2analog conversion\n",
    "    states = data['state'].apply(lambda x: int2analog(x, n=state_bit_length))\n",
    "    actions = data['action'].apply(lambda x: int2analog(x, n=action_bit_length))\n",
    "    next_states = data['next_state'].apply(lambda x: int2analog(x, n=state_bit_length))\n",
    "    # Keep rewards as float\n",
    "    rewards = torch.tensor(data['reward'].values, dtype=torch.float32)\n",
    "    # Keep done as boolean\n",
    "    dones = torch.tensor(data['done'].values, dtype=torch.bool)\n",
    "    # Combine into a single dataset\n",
    "    processed_data = list(zip(states, actions, rewards, next_states, dones))\n",
    "    return processed_data\n",
    "\n",
    "# How many bits to use for the state and action representations\n",
    "state_bit_length = 10\n",
    "action_bit_length = 10\n",
    "\n",
    "# Preprocess the data\n",
    "processed_data = preprocess_data(dataset, state_bit_length, action_bit_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.]), tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.]), tensor(-1.), tensor([-1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.]), tensor(False))\n"
     ]
    }
   ],
   "source": [
    "print(processed_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Hyperparameters\n",
    "\n",
    "Based on the paper's description, here we will define a similar (but simpler) architecture for the diffusion policy and Q networks. We will also determine the hyperparameters necessary for training the Diffusion Q-Learning model within the constraints of the Taxi environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.q1_model = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        self.q2_model = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, 1))\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=-1)\n",
    "        return self.q1_model(x), self.q2_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete Diffusion Actor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteDiffusionActor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
    "        super(DiscreteDiffusionActor, self).__init__()\n",
    "        # Define the network layers\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(hidden_dim, action_dim))\n",
    "\n",
    "    def forward(self, state):\n",
    "        return torch.softmax(self.network(state), dim=-1)  # Softmax for probability distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corruption Process and noise schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    Generates a cosine noise schedule.\n",
    "\n",
    "    Args:\n",
    "    - timesteps (int): The total number of timesteps.\n",
    "    - s (float): Scale factor for the noise level.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The beta schedule tensor.\n",
    "    \"\"\"\n",
    "    steps = torch.arange(timesteps, dtype=torch.float32) / timesteps\n",
    "    beta_schedule = s * (1 + torch.cos(torch.pi * steps)) / 2\n",
    "    return beta_schedule\n",
    "\n",
    "def compute_alpha_bar(beta_schedule):\n",
    "    alpha = 1. - beta_schedule\n",
    "    alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "    return alpha, alpha_bar\n",
    "\n",
    "def apply_noise(x, timestep, beta_schedule):\n",
    "    \"\"\"\n",
    "    Applies noise to an image x at a specific timestep.\n",
    "\n",
    "    Args:\n",
    "    - x (torch.Tensor): The initial image tensor.\n",
    "    - timestep (int): The specific timestep at which to apply noise.\n",
    "    - beta_schedule (torch.Tensor): The beta schedule tensor.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The noised version of the image at the specified timestep.\n",
    "    \"\"\"\n",
    "    # Compute alpha and alpha_bar\n",
    "    alpha, alpha_bar = compute_alpha_bar(beta_schedule)\n",
    "\n",
    "    # Ensure the timestep is within the range of the beta schedule\n",
    "    if timestep >= beta_schedule.size(0):\n",
    "        raise ValueError(\"Timestep is out of range of the beta schedule\")\n",
    "\n",
    "    # Add noise to the image at the specified timestep\n",
    "    epsilon = torch.randn_like(x)\n",
    "    xt = torch.sqrt(alpha_bar[timestep]) * x + torch.sqrt(1. - alpha_bar[timestep]) * epsilon\n",
    "\n",
    "    return xt\n",
    "\n",
    "# # Example usage\n",
    "# T = 1000  # Number of timesteps\n",
    "# beta_schedule = torch.linspace(1e-4, 0.02, T)  # Example beta schedule\n",
    "# x0 = torch.tensor([1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0])\n",
    "\n",
    "# # Apply noise recurseively for T timesteps\n",
    "# x_to_plot = []\n",
    "# xt = x0\n",
    "# for t in range(T):\n",
    "#     xt = apply_noise(xt, t, beta_schedule)\n",
    "#     if t % 100 == 0:\n",
    "#         print(\"Timestep:\", t, end=\" | \")\n",
    "#         print(\"xt:\", xt)\n",
    "#         x_to_plot.append(xt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 10  # Based on state representation\n",
    "action_dim = 2  # Based on action representation\n",
    "hidden_dim = 128  # Smaller network for a simpler task\n",
    "\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "batch_size = 64  # Size of the batch used for training\n",
    "train_epochs = 500  # Number of epochs to train for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteDiffusionQL:\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim, learning_rate, beta_schedule):\n",
    "        # Initialize actor and critic networks\n",
    "        self.actor = DiscreteDiffusionActor(state_dim, action_dim, hidden_dim)\n",
    "        self.critic = Critic(state_dim, action_dim, hidden_dim)\n",
    "\n",
    "        # Initialize optimizers for both networks\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=learning_rate)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Store the beta schedule for the diffusion process\n",
    "        self.beta_schedule = beta_schedule\n",
    "\n",
    "        # Other initializations as needed (maybe device settings, target networks if used)\n",
    "\n",
    "    def train_step(self, states, actions, rewards, next_states, dones, timestep):\n",
    "        # Apply noise to states for the diffusion process\n",
    "        noised_states = apply_noise(states, timestep, self.beta_schedule)\n",
    "\n",
    "        # TODO: Implement the training logic\n",
    "        # This includes updating the critic and actor networks based on the sampled batch\n",
    "        # Compute losses, perform backward passes, and update network weights\n",
    "\n",
    "        # Return any metrics or losses for logging\n",
    "\n",
    "    # Other things as needed (e.g., for evaluation, saving/loading models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Diffusion Q-Learning Model\n",
    "\n",
    "In this section, we will implement the training loop for the Diffusion Q-Learning model using the taxi_q_expert_dataset. The training involves iteratively updating the policy (actor) and value function (critic) networks, focusing on minimizing both the behavior cloning loss and the Q-learning loss just like in the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Replay Buffer and Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = []\n",
    "        self.max_size = max_size\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(torch.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 completed.\n",
      "Epoch 2/500 completed.\n",
      "Epoch 3/500 completed.\n",
      "Epoch 4/500 completed.\n",
      "Epoch 5/500 completed.\n",
      "Epoch 6/500 completed.\n",
      "Epoch 7/500 completed.\n",
      "Epoch 8/500 completed.\n",
      "Epoch 9/500 completed.\n",
      "Epoch 10/500 completed.\n",
      "Epoch 11/500 completed.\n",
      "Epoch 12/500 completed.\n",
      "Epoch 13/500 completed.\n",
      "Epoch 14/500 completed.\n",
      "Epoch 15/500 completed.\n",
      "Epoch 16/500 completed.\n",
      "Epoch 17/500 completed.\n",
      "Epoch 18/500 completed.\n",
      "Epoch 19/500 completed.\n",
      "Epoch 20/500 completed.\n",
      "Epoch 21/500 completed.\n",
      "Epoch 22/500 completed.\n",
      "Epoch 23/500 completed.\n",
      "Epoch 24/500 completed.\n",
      "Epoch 25/500 completed.\n",
      "Epoch 26/500 completed.\n",
      "Epoch 27/500 completed.\n",
      "Epoch 28/500 completed.\n",
      "Epoch 29/500 completed.\n",
      "Epoch 30/500 completed.\n",
      "Epoch 31/500 completed.\n",
      "Epoch 32/500 completed.\n",
      "Epoch 33/500 completed.\n",
      "Epoch 34/500 completed.\n",
      "Epoch 35/500 completed.\n",
      "Epoch 36/500 completed.\n",
      "Epoch 37/500 completed.\n",
      "Epoch 38/500 completed.\n",
      "Epoch 39/500 completed.\n",
      "Epoch 40/500 completed.\n",
      "Epoch 41/500 completed.\n",
      "Epoch 42/500 completed.\n",
      "Epoch 43/500 completed.\n",
      "Epoch 44/500 completed.\n",
      "Epoch 45/500 completed.\n",
      "Epoch 46/500 completed.\n",
      "Epoch 47/500 completed.\n",
      "Epoch 48/500 completed.\n",
      "Epoch 49/500 completed.\n",
      "Epoch 50/500 completed.\n",
      "Epoch 51/500 completed.\n",
      "Epoch 52/500 completed.\n",
      "Epoch 53/500 completed.\n",
      "Epoch 54/500 completed.\n",
      "Epoch 55/500 completed.\n",
      "Epoch 56/500 completed.\n",
      "Epoch 57/500 completed.\n",
      "Epoch 58/500 completed.\n",
      "Epoch 59/500 completed.\n",
      "Epoch 60/500 completed.\n",
      "Epoch 61/500 completed.\n",
      "Epoch 62/500 completed.\n",
      "Epoch 63/500 completed.\n",
      "Epoch 64/500 completed.\n",
      "Epoch 65/500 completed.\n",
      "Epoch 66/500 completed.\n",
      "Epoch 67/500 completed.\n",
      "Epoch 68/500 completed.\n",
      "Epoch 69/500 completed.\n",
      "Epoch 70/500 completed.\n",
      "Epoch 71/500 completed.\n",
      "Epoch 72/500 completed.\n",
      "Epoch 73/500 completed.\n",
      "Epoch 74/500 completed.\n",
      "Epoch 75/500 completed.\n",
      "Epoch 76/500 completed.\n",
      "Epoch 77/500 completed.\n",
      "Epoch 78/500 completed.\n",
      "Epoch 79/500 completed.\n",
      "Epoch 80/500 completed.\n",
      "Epoch 81/500 completed.\n",
      "Epoch 82/500 completed.\n",
      "Epoch 83/500 completed.\n",
      "Epoch 84/500 completed.\n",
      "Epoch 85/500 completed.\n",
      "Epoch 86/500 completed.\n",
      "Epoch 87/500 completed.\n",
      "Epoch 88/500 completed.\n",
      "Epoch 89/500 completed.\n",
      "Epoch 90/500 completed.\n",
      "Epoch 91/500 completed.\n",
      "Epoch 92/500 completed.\n",
      "Epoch 93/500 completed.\n",
      "Epoch 94/500 completed.\n",
      "Epoch 95/500 completed.\n",
      "Epoch 96/500 completed.\n",
      "Epoch 97/500 completed.\n",
      "Epoch 98/500 completed.\n",
      "Epoch 99/500 completed.\n",
      "Epoch 100/500 completed.\n",
      "Epoch 101/500 completed.\n",
      "Epoch 102/500 completed.\n",
      "Epoch 103/500 completed.\n",
      "Epoch 104/500 completed.\n",
      "Epoch 105/500 completed.\n",
      "Epoch 106/500 completed.\n",
      "Epoch 107/500 completed.\n",
      "Epoch 108/500 completed.\n",
      "Epoch 109/500 completed.\n",
      "Epoch 110/500 completed.\n",
      "Epoch 111/500 completed.\n",
      "Epoch 112/500 completed.\n",
      "Epoch 113/500 completed.\n",
      "Epoch 114/500 completed.\n",
      "Epoch 115/500 completed.\n",
      "Epoch 116/500 completed.\n",
      "Epoch 117/500 completed.\n",
      "Epoch 118/500 completed.\n",
      "Epoch 119/500 completed.\n",
      "Epoch 120/500 completed.\n",
      "Epoch 121/500 completed.\n",
      "Epoch 122/500 completed.\n",
      "Epoch 123/500 completed.\n",
      "Epoch 124/500 completed.\n",
      "Epoch 125/500 completed.\n",
      "Epoch 126/500 completed.\n",
      "Epoch 127/500 completed.\n",
      "Epoch 128/500 completed.\n",
      "Epoch 129/500 completed.\n",
      "Epoch 130/500 completed.\n",
      "Epoch 131/500 completed.\n",
      "Epoch 132/500 completed.\n",
      "Epoch 133/500 completed.\n",
      "Epoch 134/500 completed.\n",
      "Epoch 135/500 completed.\n",
      "Epoch 136/500 completed.\n",
      "Epoch 137/500 completed.\n",
      "Epoch 138/500 completed.\n",
      "Epoch 139/500 completed.\n",
      "Epoch 140/500 completed.\n",
      "Epoch 141/500 completed.\n",
      "Epoch 142/500 completed.\n",
      "Epoch 143/500 completed.\n",
      "Epoch 144/500 completed.\n",
      "Epoch 145/500 completed.\n",
      "Epoch 146/500 completed.\n",
      "Epoch 147/500 completed.\n",
      "Epoch 148/500 completed.\n",
      "Epoch 149/500 completed.\n",
      "Epoch 150/500 completed.\n",
      "Epoch 151/500 completed.\n",
      "Epoch 152/500 completed.\n",
      "Epoch 153/500 completed.\n",
      "Epoch 154/500 completed.\n",
      "Epoch 155/500 completed.\n",
      "Epoch 156/500 completed.\n",
      "Epoch 157/500 completed.\n",
      "Epoch 158/500 completed.\n",
      "Epoch 159/500 completed.\n",
      "Epoch 160/500 completed.\n",
      "Epoch 161/500 completed.\n",
      "Epoch 162/500 completed.\n",
      "Epoch 163/500 completed.\n",
      "Epoch 164/500 completed.\n",
      "Epoch 165/500 completed.\n",
      "Epoch 166/500 completed.\n",
      "Epoch 167/500 completed.\n",
      "Epoch 168/500 completed.\n",
      "Epoch 169/500 completed.\n",
      "Epoch 170/500 completed.\n",
      "Epoch 171/500 completed.\n",
      "Epoch 172/500 completed.\n",
      "Epoch 173/500 completed.\n",
      "Epoch 174/500 completed.\n",
      "Epoch 175/500 completed.\n",
      "Epoch 176/500 completed.\n",
      "Epoch 177/500 completed.\n",
      "Epoch 178/500 completed.\n",
      "Epoch 179/500 completed.\n",
      "Epoch 180/500 completed.\n",
      "Epoch 181/500 completed.\n",
      "Epoch 182/500 completed.\n",
      "Epoch 183/500 completed.\n",
      "Epoch 184/500 completed.\n",
      "Epoch 185/500 completed.\n",
      "Epoch 186/500 completed.\n",
      "Epoch 187/500 completed.\n",
      "Epoch 188/500 completed.\n",
      "Epoch 189/500 completed.\n",
      "Epoch 190/500 completed.\n",
      "Epoch 191/500 completed.\n",
      "Epoch 192/500 completed.\n",
      "Epoch 193/500 completed.\n",
      "Epoch 194/500 completed.\n",
      "Epoch 195/500 completed.\n",
      "Epoch 196/500 completed.\n",
      "Epoch 197/500 completed.\n",
      "Epoch 198/500 completed.\n",
      "Epoch 199/500 completed.\n",
      "Epoch 200/500 completed.\n",
      "Epoch 201/500 completed.\n",
      "Epoch 202/500 completed.\n",
      "Epoch 203/500 completed.\n",
      "Epoch 204/500 completed.\n",
      "Epoch 205/500 completed.\n",
      "Epoch 206/500 completed.\n",
      "Epoch 207/500 completed.\n",
      "Epoch 208/500 completed.\n",
      "Epoch 209/500 completed.\n",
      "Epoch 210/500 completed.\n",
      "Epoch 211/500 completed.\n",
      "Epoch 212/500 completed.\n",
      "Epoch 213/500 completed.\n",
      "Epoch 214/500 completed.\n",
      "Epoch 215/500 completed.\n",
      "Epoch 216/500 completed.\n",
      "Epoch 217/500 completed.\n",
      "Epoch 218/500 completed.\n",
      "Epoch 219/500 completed.\n",
      "Epoch 220/500 completed.\n",
      "Epoch 221/500 completed.\n",
      "Epoch 222/500 completed.\n",
      "Epoch 223/500 completed.\n",
      "Epoch 224/500 completed.\n",
      "Epoch 225/500 completed.\n",
      "Epoch 226/500 completed.\n",
      "Epoch 227/500 completed.\n",
      "Epoch 228/500 completed.\n",
      "Epoch 229/500 completed.\n",
      "Epoch 230/500 completed.\n",
      "Epoch 231/500 completed.\n",
      "Epoch 232/500 completed.\n",
      "Epoch 233/500 completed.\n",
      "Epoch 234/500 completed.\n",
      "Epoch 235/500 completed.\n",
      "Epoch 236/500 completed.\n",
      "Epoch 237/500 completed.\n",
      "Epoch 238/500 completed.\n",
      "Epoch 239/500 completed.\n",
      "Epoch 240/500 completed.\n",
      "Epoch 241/500 completed.\n",
      "Epoch 242/500 completed.\n",
      "Epoch 243/500 completed.\n",
      "Epoch 244/500 completed.\n",
      "Epoch 245/500 completed.\n",
      "Epoch 246/500 completed.\n",
      "Epoch 247/500 completed.\n",
      "Epoch 248/500 completed.\n",
      "Epoch 249/500 completed.\n",
      "Epoch 250/500 completed.\n",
      "Epoch 251/500 completed.\n",
      "Epoch 252/500 completed.\n",
      "Epoch 253/500 completed.\n",
      "Epoch 254/500 completed.\n",
      "Epoch 255/500 completed.\n",
      "Epoch 256/500 completed.\n",
      "Epoch 257/500 completed.\n",
      "Epoch 258/500 completed.\n",
      "Epoch 259/500 completed.\n",
      "Epoch 260/500 completed.\n",
      "Epoch 261/500 completed.\n",
      "Epoch 262/500 completed.\n",
      "Epoch 263/500 completed.\n",
      "Epoch 264/500 completed.\n",
      "Epoch 265/500 completed.\n",
      "Epoch 266/500 completed.\n",
      "Epoch 267/500 completed.\n",
      "Epoch 268/500 completed.\n",
      "Epoch 269/500 completed.\n",
      "Epoch 270/500 completed.\n",
      "Epoch 271/500 completed.\n",
      "Epoch 272/500 completed.\n",
      "Epoch 273/500 completed.\n",
      "Epoch 274/500 completed.\n",
      "Epoch 275/500 completed.\n",
      "Epoch 276/500 completed.\n",
      "Epoch 277/500 completed.\n",
      "Epoch 278/500 completed.\n",
      "Epoch 279/500 completed.\n",
      "Epoch 280/500 completed.\n",
      "Epoch 281/500 completed.\n",
      "Epoch 282/500 completed.\n",
      "Epoch 283/500 completed.\n",
      "Epoch 284/500 completed.\n",
      "Epoch 285/500 completed.\n",
      "Epoch 286/500 completed.\n",
      "Epoch 287/500 completed.\n",
      "Epoch 288/500 completed.\n",
      "Epoch 289/500 completed.\n",
      "Epoch 290/500 completed.\n",
      "Epoch 291/500 completed.\n",
      "Epoch 292/500 completed.\n",
      "Epoch 293/500 completed.\n",
      "Epoch 294/500 completed.\n",
      "Epoch 295/500 completed.\n",
      "Epoch 296/500 completed.\n",
      "Epoch 297/500 completed.\n",
      "Epoch 298/500 completed.\n",
      "Epoch 299/500 completed.\n",
      "Epoch 300/500 completed.\n",
      "Epoch 301/500 completed.\n",
      "Epoch 302/500 completed.\n",
      "Epoch 303/500 completed.\n",
      "Epoch 304/500 completed.\n",
      "Epoch 305/500 completed.\n",
      "Epoch 306/500 completed.\n",
      "Epoch 307/500 completed.\n",
      "Epoch 308/500 completed.\n",
      "Epoch 309/500 completed.\n",
      "Epoch 310/500 completed.\n",
      "Epoch 311/500 completed.\n",
      "Epoch 312/500 completed.\n",
      "Epoch 313/500 completed.\n",
      "Epoch 314/500 completed.\n",
      "Epoch 315/500 completed.\n",
      "Epoch 316/500 completed.\n",
      "Epoch 317/500 completed.\n",
      "Epoch 318/500 completed.\n",
      "Epoch 319/500 completed.\n",
      "Epoch 320/500 completed.\n",
      "Epoch 321/500 completed.\n",
      "Epoch 322/500 completed.\n",
      "Epoch 323/500 completed.\n",
      "Epoch 324/500 completed.\n",
      "Epoch 325/500 completed.\n",
      "Epoch 326/500 completed.\n",
      "Epoch 327/500 completed.\n",
      "Epoch 328/500 completed.\n",
      "Epoch 329/500 completed.\n",
      "Epoch 330/500 completed.\n",
      "Epoch 331/500 completed.\n",
      "Epoch 332/500 completed.\n",
      "Epoch 333/500 completed.\n",
      "Epoch 334/500 completed.\n",
      "Epoch 335/500 completed.\n",
      "Epoch 336/500 completed.\n",
      "Epoch 337/500 completed.\n",
      "Epoch 338/500 completed.\n",
      "Epoch 339/500 completed.\n",
      "Epoch 340/500 completed.\n",
      "Epoch 341/500 completed.\n",
      "Epoch 342/500 completed.\n",
      "Epoch 343/500 completed.\n",
      "Epoch 344/500 completed.\n",
      "Epoch 345/500 completed.\n",
      "Epoch 346/500 completed.\n",
      "Epoch 347/500 completed.\n",
      "Epoch 348/500 completed.\n",
      "Epoch 349/500 completed.\n",
      "Epoch 350/500 completed.\n",
      "Epoch 351/500 completed.\n",
      "Epoch 352/500 completed.\n",
      "Epoch 353/500 completed.\n",
      "Epoch 354/500 completed.\n",
      "Epoch 355/500 completed.\n",
      "Epoch 356/500 completed.\n",
      "Epoch 357/500 completed.\n",
      "Epoch 358/500 completed.\n",
      "Epoch 359/500 completed.\n",
      "Epoch 360/500 completed.\n",
      "Epoch 361/500 completed.\n",
      "Epoch 362/500 completed.\n",
      "Epoch 363/500 completed.\n",
      "Epoch 364/500 completed.\n",
      "Epoch 365/500 completed.\n",
      "Epoch 366/500 completed.\n",
      "Epoch 367/500 completed.\n",
      "Epoch 368/500 completed.\n",
      "Epoch 369/500 completed.\n",
      "Epoch 370/500 completed.\n",
      "Epoch 371/500 completed.\n",
      "Epoch 372/500 completed.\n",
      "Epoch 373/500 completed.\n",
      "Epoch 374/500 completed.\n",
      "Epoch 375/500 completed.\n",
      "Epoch 376/500 completed.\n",
      "Epoch 377/500 completed.\n",
      "Epoch 378/500 completed.\n",
      "Epoch 379/500 completed.\n",
      "Epoch 380/500 completed.\n",
      "Epoch 381/500 completed.\n",
      "Epoch 382/500 completed.\n",
      "Epoch 383/500 completed.\n",
      "Epoch 384/500 completed.\n",
      "Epoch 385/500 completed.\n",
      "Epoch 386/500 completed.\n",
      "Epoch 387/500 completed.\n",
      "Epoch 388/500 completed.\n",
      "Epoch 389/500 completed.\n",
      "Epoch 390/500 completed.\n",
      "Epoch 391/500 completed.\n",
      "Epoch 392/500 completed.\n",
      "Epoch 393/500 completed.\n",
      "Epoch 394/500 completed.\n",
      "Epoch 395/500 completed.\n",
      "Epoch 396/500 completed.\n",
      "Epoch 397/500 completed.\n",
      "Epoch 398/500 completed.\n",
      "Epoch 399/500 completed.\n",
      "Epoch 400/500 completed.\n",
      "Epoch 401/500 completed.\n",
      "Epoch 402/500 completed.\n",
      "Epoch 403/500 completed.\n",
      "Epoch 404/500 completed.\n",
      "Epoch 405/500 completed.\n",
      "Epoch 406/500 completed.\n",
      "Epoch 407/500 completed.\n",
      "Epoch 408/500 completed.\n",
      "Epoch 409/500 completed.\n",
      "Epoch 410/500 completed.\n",
      "Epoch 411/500 completed.\n",
      "Epoch 412/500 completed.\n",
      "Epoch 413/500 completed.\n",
      "Epoch 414/500 completed.\n",
      "Epoch 415/500 completed.\n",
      "Epoch 416/500 completed.\n",
      "Epoch 417/500 completed.\n",
      "Epoch 418/500 completed.\n",
      "Epoch 419/500 completed.\n",
      "Epoch 420/500 completed.\n",
      "Epoch 421/500 completed.\n",
      "Epoch 422/500 completed.\n",
      "Epoch 423/500 completed.\n",
      "Epoch 424/500 completed.\n",
      "Epoch 425/500 completed.\n",
      "Epoch 426/500 completed.\n",
      "Epoch 427/500 completed.\n",
      "Epoch 428/500 completed.\n",
      "Epoch 429/500 completed.\n",
      "Epoch 430/500 completed.\n",
      "Epoch 431/500 completed.\n",
      "Epoch 432/500 completed.\n",
      "Epoch 433/500 completed.\n",
      "Epoch 434/500 completed.\n",
      "Epoch 435/500 completed.\n",
      "Epoch 436/500 completed.\n",
      "Epoch 437/500 completed.\n",
      "Epoch 438/500 completed.\n",
      "Epoch 439/500 completed.\n",
      "Epoch 440/500 completed.\n",
      "Epoch 441/500 completed.\n",
      "Epoch 442/500 completed.\n",
      "Epoch 443/500 completed.\n",
      "Epoch 444/500 completed.\n",
      "Epoch 445/500 completed.\n",
      "Epoch 446/500 completed.\n",
      "Epoch 447/500 completed.\n",
      "Epoch 448/500 completed.\n",
      "Epoch 449/500 completed.\n",
      "Epoch 450/500 completed.\n",
      "Epoch 451/500 completed.\n",
      "Epoch 452/500 completed.\n",
      "Epoch 453/500 completed.\n",
      "Epoch 454/500 completed.\n",
      "Epoch 455/500 completed.\n",
      "Epoch 456/500 completed.\n",
      "Epoch 457/500 completed.\n",
      "Epoch 458/500 completed.\n",
      "Epoch 459/500 completed.\n",
      "Epoch 460/500 completed.\n",
      "Epoch 461/500 completed.\n",
      "Epoch 462/500 completed.\n",
      "Epoch 463/500 completed.\n",
      "Epoch 464/500 completed.\n",
      "Epoch 465/500 completed.\n",
      "Epoch 466/500 completed.\n",
      "Epoch 467/500 completed.\n",
      "Epoch 468/500 completed.\n",
      "Epoch 469/500 completed.\n",
      "Epoch 470/500 completed.\n",
      "Epoch 471/500 completed.\n",
      "Epoch 472/500 completed.\n",
      "Epoch 473/500 completed.\n",
      "Epoch 474/500 completed.\n",
      "Epoch 475/500 completed.\n",
      "Epoch 476/500 completed.\n",
      "Epoch 477/500 completed.\n",
      "Epoch 478/500 completed.\n",
      "Epoch 479/500 completed.\n",
      "Epoch 480/500 completed.\n",
      "Epoch 481/500 completed.\n",
      "Epoch 482/500 completed.\n",
      "Epoch 483/500 completed.\n",
      "Epoch 484/500 completed.\n",
      "Epoch 485/500 completed.\n",
      "Epoch 486/500 completed.\n",
      "Epoch 487/500 completed.\n",
      "Epoch 488/500 completed.\n",
      "Epoch 489/500 completed.\n",
      "Epoch 490/500 completed.\n",
      "Epoch 491/500 completed.\n",
      "Epoch 492/500 completed.\n",
      "Epoch 493/500 completed.\n",
      "Epoch 494/500 completed.\n",
      "Epoch 495/500 completed.\n",
      "Epoch 496/500 completed.\n",
      "Epoch 497/500 completed.\n",
      "Epoch 498/500 completed.\n",
      "Epoch 499/500 completed.\n",
      "Epoch 500/500 completed.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train_diffusion_ql(model, replay_buffer, epochs, batch_size, num_timesteps, beta_schedule):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(len(replay_buffer) // batch_size):\n",
    "            # Sample a batch from the replay buffer\n",
    "            states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "\n",
    "            # Apply noise to states for the diffusion process\n",
    "            timestep = np.random.randint(0, num_timesteps)\n",
    "            noised_states = apply_noise(states, timestep, beta_schedule)\n",
    "\n",
    "            # TODO: Update the critic network\n",
    "            # Compute the critic loss and perform a backward pass\n",
    "\n",
    "            # TODO: Update the actor (diffusion policy) network\n",
    "            # Compute the actor loss and perform a backward pass\n",
    "\n",
    "        # TODO: Additional logic for logging, validation, saving models, etc.\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed.\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_timesteps = 1000  # Number of timesteps for the diffusion process\n",
    "beta_schedule = cosine_beta_schedule(num_timesteps)  # Beta schedule\n",
    "\n",
    "# Initialize your model (Diffusion Q-Learning model)\n",
    "model = DiscreteDiffusionQL(state_dim, action_dim, hidden_dim, learning_rate, beta_schedule)\n",
    "\n",
    "# Initialize the replay buffer and populate it\n",
    "replay_buffer = ReplayBuffer(max_size=10000)\n",
    "for state, action, reward, next_state, done in processed_data:\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "train_diffusion_ql(model, replay_buffer, epochs=train_epochs, batch_size=batch_size, num_timesteps=num_timesteps, beta_schedule=beta_schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (Diffusion Q-Learning model)\n",
    "model = DiscreteDiffusionQL(...)\n",
    "\n",
    "# Initialize the replay buffer and populate it\n",
    "replay_buffer = ReplayBuffer(max_size=10000)\n",
    "for state, action, reward, next_state, done in processed_data:\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "# Train the model\n",
    "num_timesteps = 1000  # Number of timesteps for the diffusion process\n",
    "beta_schedule = cosine_beta_schedule(num_timesteps)  # Beta schedule\n",
    "train_diffusion_ql(model, replay_buffer, epochs=train_epochs, batch_size=batch_size, num_timesteps=num_timesteps, beta_schedule=beta_schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "After training, we evaluate the Diffusion Q-Learning model using the \"taxi_expert_test\" dataset. The evaluation focuses on assessing how well the model replicates expert behavior and its effectiveness in achieving the goals of the Taxi environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    # TODO: Implement the logic to evaluate the model on the test data\n",
    "    # This could be running the model on the test data and comparing its performance against some kind of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "evaluate_model(model, taxi_expert_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work\n",
    "\n",
    "I'll use this section to summarize the findings from the training and evaluation of the Diffusion Q-Learning model in the Taxi environment. I'll discuss the model's performance, potential areas of improvement, and opportunities for future research and application in more complex environments. This will serve as a useful reference when writing the thesis and/or paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
